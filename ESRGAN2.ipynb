{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2Ioha0Qm/vVBBQoL/37/z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tnshq/esrgan/blob/main/ESRGAN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "Vtaph9TnNFKK",
        "outputId": "425b4735-4f65-4581-aecb-1ff591b042d0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'BSDS300/images/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4c9638772f3a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Create Dataset and DataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BSDS300/images/train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-4c9638772f3a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root_dir, transform)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'BSDS300/images/train'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from torchvision.utils import save_image\n",
        "from google.colab import files\n",
        "\n",
        "# Define dataset class for loading and preprocessing images\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = os.listdir(root_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
        "        image = Image.open(img_name).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "# Define transforms (resize images for simplicity)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Create Dataset and DataLoader\n",
        "dataset = ImageDataset(root_dir=\"BSDS300/images/train\", transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "class RRDB(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(RRDB, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.conv1(x))\n",
        "        out = self.relu(self.conv2(out))\n",
        "        out = self.conv3(out)\n",
        "        return x + out  # Residual connection\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_rrdb=23):\n",
        "        super(Generator, self).__init__()\n",
        "        self.initial_conv = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1)\n",
        "        self.rrdb_blocks = nn.Sequential(*[RRDB(64) for _ in range(num_rrdb)])\n",
        "        self.final_conv = nn.Conv2d(64, in_channels, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        initial_feature = self.initial_conv(x)\n",
        "        out = self.rrdb_blocks(initial_feature)\n",
        "        out = self.final_conv(out)\n",
        "        return out\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super(Discriminator, self).__init__()\n",
        "        def block(in_feat, out_feat, normalize=True):\n",
        "            layers = [nn.Conv2d(in_feat, out_feat, 4, stride=2, padding=1)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm2d(out_feat))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(in_channels, 64, normalize=False),\n",
        "            *block(64, 128),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            nn.Conv2d(512, 1, 3, stride=1, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)\n",
        "\n",
        "class ContentLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ContentLoss, self).__init__()\n",
        "\n",
        "    def forward(self, sr, hr):\n",
        "        return F.mse_loss(sr, hr)\n",
        "\n",
        "class PerceptualLoss(nn.Module):\n",
        "    def __init__(self, vgg_model):\n",
        "        super(PerceptualLoss, self).__init__()\n",
        "        self.vgg = vgg_model.features[:36]  # Use pre-trained VGG features\n",
        "        self.vgg.eval()\n",
        "\n",
        "    def forward(self, sr, hr):\n",
        "        sr_features = self.vgg(sr)\n",
        "        hr_features = self.vgg(hr)\n",
        "        return F.mse_loss(sr_features, hr_features)\n",
        "\n",
        "def save_checkpoint(epoch, generator, optimizer_G, discriminator, optimizer_D, path='./esrgan_checkpoint.pth'):\n",
        "    \"\"\"Saves the model and optimizer states to a checkpoint file.\"\"\"\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'generator_state_dict': generator.state_dict(),\n",
        "        'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
        "        'discriminator_state_dict': discriminator.state_dict(),\n",
        "        'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
        "    }, path)\n",
        "\n",
        "def load_checkpoint(path='./esrgan_checkpoint.pth'):\n",
        "    \"\"\"Loads the model and optimizer states from a checkpoint file.\"\"\"\n",
        "    checkpoint = torch.load(path)\n",
        "    return checkpoint['epoch'], checkpoint['generator_state_dict'], checkpoint['optimizer_G_state_dict'], checkpoint['discriminator_state_dict'], checkpoint['optimizer_D_state_dict']\n",
        "\n",
        "def train(generator, discriminator, dataloader, num_epochs, optimizer_G, optimizer_D, criterion_content, criterion_perceptual, device, start_epoch=0):\n",
        "    \"\"\"Trains the ESRGAN model.\"\"\"\n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        for i, img in enumerate(dataloader):\n",
        "            img = img.to(device)\n",
        "\n",
        "            # Generate super-resolved image\n",
        "            sr_image = generator(img)\n",
        "\n",
        "            # Train Generator\n",
        "            optimizer_G.zero_grad()\n",
        "            content_loss = criterion_content(sr_image, img)\n",
        "            perceptual_loss = criterion_perceptual(sr_image, img)\n",
        "            g_loss = content_loss + perceptual_loss\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            # Train Discriminator\n",
        "            optimizer_D.zero_grad()\n",
        "            real_output = discriminator(img)\n",
        "            fake_output = discriminator(sr_image.detach())\n",
        "            d_loss = F.binary_cross_entropy_with_logits(real_output, torch.ones_like(real_output)) + \\\n",
        "                     F.binary_cross_entropy_with_logits(fake_output, torch.zeros_like(fake_output))\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Epoch {epoch}/{num_epochs}, Step {i}, G Loss: {g_loss.item()}, D Loss: {d_loss.item()}\")\n",
        "\n",
        "        # Save checkpoint after each epoch\n",
        "        save_checkpoint(epoch, generator, optimizer_G, discriminator, optimizer_D)\n",
        "\n",
        "def enhance_image(image_path, generator, device):\n",
        "    \"\"\"Enhances the resolution of an image using the ESRGAN model.\"\"\"\n",
        "    # Load the image\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    # Preprocess the image\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),  # Resize to match training data\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Enhance the image using the generator\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        enhanced_image = generator(image)\n",
        "\n",
        "    # Postprocess the enhanced image\n",
        "    enhanced_image = enhanced_image.squeeze().cpu().numpy()\n",
        "    enhanced_image = np.transpose(enhanced_image, (1, 2, 0))\n",
        "    enhanced_image = (enhanced_image * 255).astype(np.uint8)  # Convert to uint8\n",
        "\n",
        "    return enhanced_image\n",
        "\n",
        "# Initialize device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize models and optimizers\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "\n",
        "# Load pre-trained VGG model for Perceptual Loss\n",
        "vgg = models.vgg19(pretrained=True).to(device)\n",
        "criterion_content = ContentLoss()\n",
        "criterion_perceptual = PerceptualLoss(vgg)\n",
        "\n",
        "# Load checkpoint if available\n",
        "start_epoch = 0\n",
        "if os.path.exists('./esrgan_checkpoint.pth'):\n",
        "    start_epoch, generator_state_dict, optimizer_G_state_dict, discriminator_state_dict, optimizer_D_state_dict = load_checkpoint()\n",
        "    generator.load_state_dict(generator_state_dict)\n",
        "    optimizer_G.load_state_dict(optimizer_G_state_dict)\n",
        "    discriminator.load_state_dict(discriminator_state_dict)\n",
        "    optimizer_D.load_state_dict(optimizer_D_state_dict)\n",
        "    print(f\"Resuming training from epoch {start_epoch}\")\n",
        "\n",
        "# Train ESRGAN\n",
        "train(generator, discriminator, dataloader, num_epochs=2, optimizer_G=optimizer_G, optimizer_D=optimizer_D,\n",
        "      criterion_content=criterion_content, criterion_perceptual=criterion_perceptual, device=device, start_epoch=start_epoch)\n",
        "\n",
        "# Get input image from the user\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Enhance the image\n",
        "enhanced_image = enhance_image(image_path, generator, device)\n",
        "\n",
        "# Display the enhanced image\n",
        "plt.imshow(enhanced_image)\n",
        "plt.title(\"Enhanced Image\")\n",
        "plt.show()"
      ]
    }
  ]
}